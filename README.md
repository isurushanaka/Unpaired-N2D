### Introduction
This study represents a utilization of Cycle-GAN for night-to-day (N2D) image translation.

### Note
We are unable to share our training details as our paper is still being reviewed. Once our paper is published, we will publish all of our codes. However, we have shared our dataset and Pytorch implementation of the generator and the discriminator. If anyone is interested, we will share the weights for the generator and the discriminator. 

### Dataset
The day-time images are composed of images from the [Oxford RobotCar dataset](https://robotcar-dataset.robots.ox.ac.uk/datasets/), the [ZJU dataset](https://github.com/elnino9ykl/ZJU-Dataset), the [BDD100K dataset] (https://github.com/bdd100k/bdd100k), and the images form driving Downtown videos shared by [J Utah](https://www.youtube.com/channel/UCBcVQr-07MH-p9e2kRTdB3A).
The datset can be downloaded from this [link](https://drive.google.com/drive/folders/1OniXQ1b2oj8CMF-9nl3T101mZOYxq4W4?usp=sharing)


Disclaimer: Please note no copyright infrignement is intended, and we do not own nor claim to own any of the video shared by [J Utah](https://www.youtube.com/channel/UCBcVQr-07MH-p9e2kRTdB3A)
